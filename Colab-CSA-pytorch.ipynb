{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-CSA-pytorch.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsdJTZdA35vE",
        "colab_type": "text"
      },
      "source": [
        "# Colab-CSA (pytorch)\n",
        "Original repo: [KumapowerLIU/CSA-inpainting](https://github.com/KumapowerLIU/CSA-inpainting)\n",
        "\n",
        "Yukariin's repo: [Yukariin/CSA_pytorch](https://github.com/Yukariin/CSA_pytorch)\n",
        "Thank you Yukariin for fixing the broken original.\n",
        "\n",
        "Differentiable Augmentation: [mit-han-lab/data-efficient-gans](https://github.com/mit-han-lab/data-efficient-gans)\n",
        "\n",
        "My fork: [styler00dollar/Colab-CSA-pytorch](https://github.com/styler00dollar/Colab-CSA-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFHMIiC75LGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yzQ5bF67ObG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install\n",
        "!git clone https://github.com/Yukariin/CSA_pytorch\n",
        "%cd /content/\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install pytorch==1.1 cudatoolkit torchvision -c pytorch -y\n",
        "!conda install ipykernel -y\n",
        "!pip install tensorboardX\n",
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlhMA0dC-mXP",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "Warning: It saves into the folder named ckpt. If you only create save_dir, then it will crash during saving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX3kkedeBgDa",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Create empty folders\n",
        "!mkdir /content/root\n",
        "!mkdir /content/save_dir\n",
        "!mkdir /content/save_dir/ckpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn1TbVsmRbPh",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Adding Differentiable Augmentation in loss.py (experimental)\n",
        "%%writefile /content/CSA_pytorch/loss.py \n",
        "# Differentiable Augmentation for Data-Efficient GAN Training\n",
        "# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n",
        "# https://arxiv.org/pdf/2006.10738\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def DiffAugment(x, policy='', channels_first=True):\n",
        "    if policy:\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "        for p in policy.split(','):\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x)\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_brightness(x):\n",
        "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_saturation(x):\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_contrast(x):\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_translation(x, ratio=0.125):\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_cutout(x, ratio=0.5):\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "\n",
        "AUGMENT_FNS = {\n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'translation': [rand_translation],\n",
        "    'cutout': [rand_cutout],\n",
        "}\n",
        "\n",
        "policy = 'color,translation,cutout'\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2 # [-1,1] -> [0,1]\n",
        "    return out.clamp_(0, 1)\n",
        "\n",
        "\n",
        "class VGG16FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "        self.enc_1 = nn.Sequential(*vgg16.features[:5])\n",
        "        self.enc_2 = nn.Sequential(*vgg16.features[5:10])\n",
        "        self.enc_3 = nn.Sequential(*vgg16.features[10:17])\n",
        "        self.enc_4 = nn.Sequential(*vgg16.features[17:23])\n",
        "\n",
        "        #print(self.enc_1)\n",
        "        #print(self.enc_2)\n",
        "        #print(self.enc_3)\n",
        "        #print(self.enc_4)\n",
        "\n",
        "        # fix the encoder\n",
        "        for i in range(4):\n",
        "            for param in getattr(self, 'enc_{:d}'.format(i + 1)).parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, image):\n",
        "        results = [image]\n",
        "        for i in range(4):\n",
        "            func = getattr(self, 'enc_{:d}'.format(i + 1))\n",
        "            results.append(func(results[-1]))\n",
        "        return results[1:]\n",
        "    \n",
        "\n",
        "class ConsistencyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.normalize = transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "        self.vgg = VGG16FeatureExtractor()\n",
        "        self.l2 = nn.MSELoss()\n",
        "\n",
        "    def forward(self, csa, csa_d, target, mask):\n",
        "        # https://pytorch.org/docs/stable/torchvision/models.html\n",
        "        # Pre-trained VGG16 model expect input images normalized in the same way.\n",
        "        # The images have to be loaded in to a range of [0, 1]\n",
        "        # and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n",
        "        t = denorm(target) # [-1,1] -> [0,1]\n",
        "        t = self.normalize(t[0]) # BxCxHxW -> CxHxW -> normalize\n",
        "        t = t.unsqueeze(0) # CxHxW -> BxCxHxW\n",
        "\n",
        "        vgg_gt = self.vgg(t)\n",
        "        vgg_gt = vgg_gt[-1]\n",
        "\n",
        "        mask_r = F.interpolate(mask, size=csa.size()[2:])\n",
        "\n",
        "        lossvalue = self.l2(csa*mask_r, vgg_gt*mask_r) + self.l2(csa_d*mask_r, vgg_gt*mask_r)\n",
        "        return lossvalue\n",
        "\n",
        "\n",
        "def calc_gan_loss(discriminator, output, target):\n",
        "    # Either here or down below should be diffaug applied. Needs to be tested.\n",
        "    #output = DiffAugment(output, policy=policy)\n",
        "    #target = DiffAugment(target, policy=policy)\n",
        "\n",
        "    y_pred_fake = discriminator(output, target)\n",
        "    y_pred = discriminator(target, output)\n",
        "\n",
        "    y_pred_fake = DiffAugment(y_pred_fake, policy=policy)\n",
        "    y_pred = DiffAugment(y_pred, policy=policy)\n",
        "\n",
        "    g_loss = (torch.mean((y_pred - torch.mean(y_pred_fake) + 1.) ** 2) + torch.mean((y_pred_fake - torch.mean(y_pred) - 1.) ** 2))/2\n",
        "    d_loss = (torch.mean((y_pred - torch.mean(y_pred_fake) - 1.) ** 2) + torch.mean((y_pred_fake - torch.mean(y_pred) + 1.) ** 2))/2\n",
        "\n",
        "    return g_loss, d_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSsXXEQK5Lrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/CSA_pytorch\n",
        "!python /content/CSA_pytorch/train.py --root /content/root --save_dir /content/save_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8pTHarJ-j6Y",
        "colab_type": "text"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhVfzBK96e-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/CSA_pytorch/test.py --image /content/image.png \\\n",
        "--mask /content/mask.png --output /content/output.png \\\n",
        "--checkpoint /content/save_dir/ckpt/G_10000.pth"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}